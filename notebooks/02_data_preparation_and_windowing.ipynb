{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "bd7a00af",
            "metadata": {},
            "source": [
                "# 02 - Data Preparation and Window Creation for LSTM\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "643734b2",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from sklearn.preprocessing import MinMaxScaler"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "ccad6fa7",
            "metadata": {},
            "outputs": [],
            "source": [
                "path = \"../data/raw/continuous_dataset.csv\"\n",
                "\n",
                "df = pd.read_csv(\n",
                "    path,\n",
                "    parse_dates=['datetime'],\n",
                "    index_col='datetime'\n",
                ").sort_index()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "868b44e7",
            "metadata": {},
            "outputs": [],
            "source": [
                "df['hour'] = df.index.hour\n",
                "df['dayofweek'] = df.index.day_of_week\n",
                "df['is_weekend'] = (df['dayofweek'] >= 5).astype(int)\n",
                "\n",
                "feature_cols = [\n",
                "    'nat_demand',\n",
                "    'T2M_toc', 'T2M_san', 'T2M_dav',\n",
                "    'hour', 'dayofweek', 'is_weekend',\n",
                "    'holiday', 'school'\n",
                "]\n",
                "\n",
                "target_col = 'nat_demand'\n",
                "\n",
                "df_model = df[feature_cols].copy()\n",
                "df_model.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "6b571567",
            "metadata": {},
            "outputs": [],
            "source": [
                "n = len(df_model)\n",
                "train_size = int(n * 0.8)\n",
                "\n",
                "df_train = df_model.iloc[:train_size]\n",
                "df_test  = df_model.iloc[train_size:]\n",
                "\n",
                "print(\"Train:\", df_train.index.min(), \"→\", df_train.index.max(), \"| rows:\", len(df_train))\n",
                "print(\"Test: \", df_test.index.min(), \"→\", df_test.index.max(),  \"| rows:\", len(df_test))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ef7ae559",
            "metadata": {},
            "source": [
                "#### Scaling"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "b425a529",
            "metadata": {},
            "outputs": [],
            "source": [
                "X_train = df_train[feature_cols].values\n",
                "y_train = df_train[[target_col]].values   # double [] -> 2D\n",
                "\n",
                "X_test  = df_test[feature_cols].values\n",
                "y_test  = df_test[[target_col]].values\n",
                "\n",
                "scaler_X = MinMaxScaler()\n",
                "scaler_y = MinMaxScaler()\n",
                "\n",
                "X_train_scaled = scaler_X.fit_transform(X_train)   # fit ONLY on train\n",
                "y_train_scaled = scaler_y.fit_transform(y_train)\n",
                "\n",
                "X_test_scaled  = scaler_X.transform(X_test)        # use same params\n",
                "y_test_scaled  = scaler_y.transform(y_test)\n",
                "\n",
                "print(X_train_scaled.shape, y_train_scaled.shape, X_test_scaled.shape, y_test_scaled.shape)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "44dbdf05",
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_sequences(X, y, seq_len):\n",
                "    Xs, ys = [], []\n",
                "    for i in range(seq_len, len(X)):\n",
                "        Xs.append(X[i-seq_len:i])  # [t-seq_len, ..., t-1]\n",
                "        ys.append(y[i])            # value at t\n",
                "    return np.array(Xs), np.array(ys)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "0d21418a",
            "metadata": {},
            "outputs": [],
            "source": [
                "sequence_length = 24 * 7  # 7 days of history (168 hours)\n",
                "\n",
                "X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train_scaled, sequence_length)\n",
                "X_test_seq,  y_test_seq  = create_sequences(X_test_scaled,  y_test_scaled,  sequence_length)\n",
                "\n",
                "print(\"X_train_seq:\", X_train_seq.shape)\n",
                "print(\"y_train_seq:\", y_train_seq.shape)\n",
                "print(\"X_test_seq :\", X_test_seq.shape)\n",
                "print(\"y_test_seq :\", y_test_seq.shape)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "6dc17dd5",
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "from torch.utils.data import TensorDataset, DataLoader\n",
                "\n",
                "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "print(\"Using device:\", device)\n",
                "\n",
                "X_train_tensor = torch.tensor(X_train_seq, dtype=torch.float32).to(device)\n",
                "y_train_tensor = torch.tensor(y_train_seq, dtype=torch.float32).to(device)\n",
                "\n",
                "X_test_tensor  = torch.tensor(X_test_seq,  dtype=torch.float32).to(device)\n",
                "y_test_tensor  = torch.tensor(y_test_seq,  dtype=torch.float32).to(device)\n",
                "\n",
                "X_train_tensor.shape, y_train_tensor.shape\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "faea18af",
            "metadata": {},
            "outputs": [],
            "source": [
                "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
                "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
                "\n",
                "batch_size = 64\n",
                "train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
                "test_loader = DataLoader(test_dataset, batch_size, shuffle=False)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "0fc7c9d1",
            "metadata": {},
            "outputs": [],
            "source": [
                "for X_batch, y_batch in train_loader:\n",
                "    print(X_batch.shape, y_batch.shape)\n",
                "    break\n",
                "print(len(train_loader))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "4a5f5023",
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch.nn as nn \n",
                "\n",
                "class LSTMForecast(nn.Module): \n",
                "    def __init__(self, input_size, hidden_size=64, num_layers=2, output_size=1):\n",
                "        super().__init__()\n",
                "        # LSTM Layer\n",
                "        self.lstm = nn.LSTM(\n",
                "            input_size=input_size,\n",
                "            hidden_size=hidden_size,\n",
                "            num_layers=num_layers,\n",
                "            batch_first=True\n",
                "        )\n",
                "        # Final linear layer \n",
                "        self.fc = nn.Linear(hidden_size, 1)\n",
                "    \n",
                "    def forward(self, x):\n",
                "        # x: (batch_size, seq_len, input_size)\n",
                "        out, _ = self.lstm(x)\n",
                "\n",
                "        last_hidden = out[:, -1, :]\n",
                "        out = self.fc(last_hidden)\n",
                "        return out\n",
                "        "
            ]
        },
        {
            "cell_type": "markdown",
            "id": "261c3da7",
            "metadata": {},
            "source": [
                "I have a batch of 64 windows.\n",
                "Each window represents 7 days (168 hours) and, in each hour, I have 9 features.\n",
                "\n",
                "The LSTM is one single model (not 64 distinct ones) processing the 64 windows in parallel.\n",
                "If I zoom in on a single window:\n",
                "\n",
                "the LSTM iterates through the 168 hours in chronological order,\n",
                "\n",
                "at each step it sees a vector of 9 features (that hour) and updates an internal state (hidden) of size 64,\n",
                "\n",
                "at the end of hour 168, I keep the last hidden state, which is a summary of what happened in those 168 hours.\n",
                "\n",
                "That vector of size 64 is passed through a final layer (fc) to obtain a prediction of the demand for the next hour.\n",
                "\n",
                "This same process happens for all 64 windows in the batch in parallel, so I get 64 predictions.\n",
                "I compare those 64 predictions with the 64 actual values (y_batch), calculate the loss (for example the average MSE), and use that to adjust the weights of the LSTM and the final layer so that next time it predicts better."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "061cc50c",
            "metadata": {},
            "outputs": [],
            "source": [
                "input_size = X_train_seq.shape[2]\n",
                "\n",
                "model = LSTMForecast(input_size).to(device)\n",
                "\n",
                "model\n",
                "\n",
                "criterion = nn.MSELoss()\n",
                "\n",
                "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
                "\n",
                "print(model)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "id": "adaa6772",
            "metadata": {},
            "outputs": [],
            "source": [
                "n_epochs = 15\n",
                "\n",
                "for epoch in range(n_epochs):\n",
                "    #train\n",
                "    model.train()\n",
                "    train_loss = 0.0\n",
                "\n",
                "    for X_batch, y_batch in train_loader:\n",
                "        optimizer.zero_grad() # clear previous gradients\n",
                "        y_pred = model(X_batch) # forward: LSTM + fc\n",
                "        loss = criterion(y_pred, y_batch) # MSE between preds and targets\n",
                "        loss.backward() # backprop: calc gradients\n",
                "        optimizer.step() # update model weights\n",
                "\n",
                "        train_loss += loss.item() * X_batch.size(0)\n",
                "\n",
                "    train_loss /= len(train_loader.dataset)\n",
                "        \n",
                "    all_pred = []\n",
                "    # Validation \n",
                "    model.eval()\n",
                "    val_loss = 0.0\n",
                "    with torch.no_grad():\n",
                "        for X_batch, y_batch in test_loader:\n",
                "            y_pred = model(X_batch)\n",
                "            loss = criterion(y_pred, y_batch)\n",
                "            val_loss += loss.item() * X_batch.size(0)\n",
                "            \n",
                "            all_pred.append(y_pred)\n",
                "    all_pred = torch.cat(all_pred, dim=0)\n",
                "    all_pred = all_pred.cpu().numpy()\n",
                "    \n",
                "\n",
                "    val_loss /= len(test_loader.dataset)\n",
                "    if (epoch+1) % 1 == 0:\n",
                "        print(f\"Epoch {epoch+1}: train_loss={train_loss:.6f}, val_loss={val_loss:.6f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "id": "95b699a8",
            "metadata": {},
            "outputs": [],
            "source": [
                "y_test_true = scaler_y.inverse_transform(y_test_seq)\n",
                "y_test_pred  = scaler_y.inverse_transform(all_pred)\n",
                "y_test_pred.shape, y_test_true.shape"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "36daa581",
            "metadata": {},
            "source": [
                "### Metrics Calculation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "id": "dbb45400",
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
                "\n",
                "mse = mean_squared_error(y_test_pred, y_test_true)\n",
                "mae = mean_absolute_error(y_test_pred, y_test_true)\n",
                "\n",
                "rmse = mse ** 0.5 \n",
                "\n",
                "print(f\"MAE: {mae:.2f}\")\n",
                "print(f\"MSE: {mse:.2f}\")\n",
                "print(f\"RMSE: {rmse:.2f}\") # Usually same unit as target and not squared like MSE\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1e69af64",
            "metadata": {},
            "source": [
                "#### Plotting"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "id": "6ec2c87d",
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Visualize a segment\n",
                "plt.figure(figsize=(12, 6))\n",
                "plt.plot(y_test_true[:200], label='Real')\n",
                "plt.plot(y_test_pred[:200], label='Predicted')\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}