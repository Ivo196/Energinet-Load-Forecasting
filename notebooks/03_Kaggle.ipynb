{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "17d4ff59-26eb-46f6-bd86-3064e5c3f976",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-12-22T13:41:53.993650Z",
                    "iopub.status.busy": "2025-12-22T13:41:53.993383Z",
                    "iopub.status.idle": "2025-12-22T13:41:54.261722Z",
                    "shell.execute_reply": "2025-12-22T13:41:54.261146Z",
                    "shell.execute_reply.started": "2025-12-22T13:41:53.993628Z"
                },
                "trusted": true
            },
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import os\n",
                "\n",
                "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
                "    for filename in filenames:\n",
                "        print(os.path.join(dirname, filename))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "666e2fda-fab9-48f4-90cb-74eb05668817",
            "metadata": {},
            "source": [
                "#### Imports & Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "643734b2",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-12-22T13:41:55.841974Z",
                    "iopub.status.busy": "2025-12-22T13:41:55.841313Z",
                    "iopub.status.idle": "2025-12-22T13:42:00.147832Z",
                    "shell.execute_reply": "2025-12-22T13:42:00.147146Z",
                    "shell.execute_reply.started": "2025-12-22T13:41:55.841945Z"
                },
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Using device: cuda\n"
                    ]
                }
            ],
            "source": [
                "# 1. Environment Setup & Imports\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import os\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "from torch.utils.data import TensorDataset, DataLoader\n",
                "from sklearn.preprocessing import MinMaxScaler\n",
                "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
                "\n",
                "# Device configuration (GPU if available)\n",
                "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "print(f\"Using device: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "13de39af-ef95-4f46-9099-f1b043e8b150",
            "metadata": {},
            "source": [
                "#### Data Loading"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "ccad6fa7",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-12-22T13:43:02.378855Z",
                    "iopub.status.busy": "2025-12-22T13:43:02.378591Z",
                    "iopub.status.idle": "2025-12-22T13:43:02.570829Z",
                    "shell.execute_reply": "2025-12-22T13:43:02.570017Z",
                    "shell.execute_reply.started": "2025-12-22T13:43:02.378832Z"
                },
                "trusted": true
            },
            "outputs": [],
            "source": [
                "path = \"/kaggle/input/electricity-load-forecasting/continuous dataset.csv\"\n",
                "df = pd.read_csv(\n",
                "    path,\n",
                "    parse_dates=['datetime'],\n",
                "    index_col='datetime'\n",
                ").sort_index()\n",
                "# Simple Feature Engineering\n",
                "df['hour'] = df.index.hour\n",
                "df['dayofweek'] = df.index.day_of_week\n",
                "df['is_weekend'] = (df['dayofweek'] >= 5).astype(int)\n",
                "\n",
                "# Feature Selection\n",
                "feature_cols = [\n",
                "    'nat_demand',\n",
                "    'T2M_toc', 'T2M_san', 'T2M_dav',\n",
                "    'hour', 'dayofweek', 'is_weekend',\n",
                "    'holiday', 'school'\n",
                "]\n",
                "target_col = 'nat_demand'\n",
                "\n",
                "df_model = df[feature_cols].copy()\n",
                "df_model.head()\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ec810573-afa9-490a-a704-e349f4a9ce40",
            "metadata": {},
            "source": [
                "#### Data Preparation (Splitting & Scaling)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6b571567",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-12-22T13:43:37.009114Z",
                    "iopub.status.busy": "2025-12-22T13:43:37.008813Z",
                    "iopub.status.idle": "2025-12-22T13:43:37.024565Z",
                    "shell.execute_reply": "2025-12-22T13:43:37.023834Z",
                    "shell.execute_reply.started": "2025-12-22T13:43:37.009087Z"
                },
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Train samples: 38438\n",
                        "Test samples:  9610\n"
                    ]
                }
            ],
            "source": [
                "# 3. Data Preparation\n",
                "# Split Train/Test (80/20)\n",
                "n = len(df_model)\n",
                "train_size = int(n * 0.8)\n",
                "\n",
                "df_train = df_model.iloc[:train_size]\n",
                "df_test  = df_model.iloc[train_size:]\n",
                "\n",
                "print(f\"Train samples: {len(df_train)}\")\n",
                "print(f\"Test samples:  {len(df_test)}\")\n",
                "\n",
                "# Scaling\n",
                "# It is important to fit_transform scaling ONLY on train to avoid data leakage\n",
                "X_train = df_train[feature_cols].values\n",
                "y_train = df_train[[target_col]].values\n",
                "\n",
                "X_test  = df_test[feature_cols].values\n",
                "y_test  = df_test[[target_col]].values\n",
                "\n",
                "scaler_X = MinMaxScaler()\n",
                "scaler_y = MinMaxScaler()\n",
                "\n",
                "X_train_scaled = scaler_X.fit_transform(X_train)\n",
                "y_train_scaled = scaler_y.fit_transform(y_train)\n",
                "\n",
                "X_test_scaled  = scaler_X.transform(X_test)\n",
                "y_test_scaled  = scaler_y.transform(y_test)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ef7ae559",
            "metadata": {},
            "source": [
                "#### Windowing (Sliding Window)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "44dbdf05",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-12-22T13:44:04.127905Z",
                    "iopub.status.busy": "2025-12-22T13:44:04.127568Z",
                    "iopub.status.idle": "2025-12-22T13:44:04.781842Z",
                    "shell.execute_reply": "2025-12-22T13:44:04.781213Z",
                    "shell.execute_reply.started": "2025-12-22T13:44:04.127880Z"
                },
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# 4. Sliding Window Creation\n",
                "def create_sequences(X, y, seq_len):\n",
                "    \"\"\"\n",
                "    Creates training sequences (X) and targets (y).\n",
                "    X: (samples, seq_len, features)\n",
                "    y: (samples, 1)\n",
                "    \"\"\"\n",
                "    Xs, ys = [], []\n",
                "    for i in range(seq_len, len(X)):\n",
                "        Xs.append(X[i-seq_len:i])\n",
                "        ys.append(y[i])\n",
                "    return np.array(Xs), np.array(ys)\n",
                "\n",
                "sequence_length = 24 * 7  # 168 hours (1 week of history)\n",
                "\n",
                "X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train_scaled, sequence_length)\n",
                "X_test_seq,  y_test_seq  = create_sequences(X_test_scaled,  y_test_scaled,  sequence_length)\n",
                "\n",
                "# Convert to PyTorch Tensors\n",
                "X_train_tensor = torch.tensor(X_train_seq, dtype=torch.float32).to(device)\n",
                "y_train_tensor = torch.tensor(y_train_seq, dtype=torch.float32).to(device)\n",
                "\n",
                "X_test_tensor  = torch.tensor(X_test_seq,  dtype=torch.float32).to(device)\n",
                "y_test_tensor  = torch.tensor(y_test_seq,  dtype=torch.float32).to(device)\n",
                "\n",
                "# DataLoader\n",
                "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
                "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
                "\n",
                "batch_size = 64\n",
                "train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
                "test_loader = DataLoader(test_dataset, batch_size, shuffle=False)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "90765edc-096b-4d62-8d0f-f2dd377601e7",
            "metadata": {},
            "source": [
                "#### Model Architecture"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4a5f5023",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-12-22T13:44:57.123544Z",
                    "iopub.status.busy": "2025-12-22T13:44:57.123193Z",
                    "iopub.status.idle": "2025-12-22T13:44:57.237902Z",
                    "shell.execute_reply": "2025-12-22T13:44:57.237352Z",
                    "shell.execute_reply.started": "2025-12-22T13:44:57.123514Z"
                },
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "LSTMForecast(\n",
                        "  (lstm): LSTM(9, 64, num_layers=2, batch_first=True)\n",
                        "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
                        ")\n"
                    ]
                }
            ],
            "source": [
                "# 5. Model Architecture\n",
                "class LSTMForecast(nn.Module): \n",
                "    def __init__(self, input_size, hidden_size=64, num_layers=2, output_size=1):\n",
                "        super().__init__()\n",
                "        self.lstm = nn.LSTM(\n",
                "            input_size=input_size,\n",
                "            hidden_size=hidden_size,\n",
                "            num_layers=num_layers,\n",
                "            batch_first=True\n",
                "        )\n",
                "        self.fc = nn.Linear(hidden_size, output_size)\n",
                "    \n",
                "    def forward(self, x):\n",
                "        # x shape: (batch_size, seq_len, input_size)\n",
                "        out, _ = self.lstm(x)\n",
                "        # Take the last hidden state\n",
                "        last_hidden = out[:, -1, :]\n",
                "        out = self.fc(last_hidden)\n",
                "        return out\n",
                "\n",
                "input_size = X_train_seq.shape[2]\n",
                "model = LSTMForecast(input_size).to(device)\n",
                "print(model)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "73978e7e-6036-402a-92ae-afed6a031465",
            "metadata": {},
            "source": [
                "#### Training Loop"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "061cc50c",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-12-22T13:45:20.772918Z",
                    "iopub.status.busy": "2025-12-22T13:45:20.772629Z",
                    "iopub.status.idle": "2025-12-22T13:46:56.373353Z",
                    "shell.execute_reply": "2025-12-22T13:46:56.372689Z",
                    "shell.execute_reply.started": "2025-12-22T13:45:20.772892Z"
                },
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Starting training...\n",
                        "Epoch 5/50: Train Loss=0.000457, Val Loss=0.000871\n",
                        "Epoch 10/50: Train Loss=0.000237, Val Loss=0.000423\n",
                        "Epoch 15/50: Train Loss=0.000194, Val Loss=0.000291\n",
                        "Epoch 20/50: Train Loss=0.000181, Val Loss=0.000323\n",
                        "Epoch 25/50: Train Loss=0.000175, Val Loss=0.000265\n",
                        "Epoch 30/50: Train Loss=0.000170, Val Loss=0.000303\n",
                        "Epoch 35/50: Train Loss=0.000163, Val Loss=0.000294\n",
                        "Epoch 40/50: Train Loss=0.000162, Val Loss=0.000322\n",
                        "Epoch 45/50: Train Loss=0.000155, Val Loss=0.000268\n",
                        "Epoch 50/50: Train Loss=0.000159, Val Loss=0.000238\n"
                    ]
                }
            ],
            "source": [
                "# 6. Training Loop\n",
                "criterion = nn.MSELoss()\n",
                "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
                "\n",
                "n_epochs = 50 # Increased to 50 to leverage GPU\n",
                "print(\"Starting training...\")\n",
                "\n",
                "for epoch in range(n_epochs):\n",
                "    model.train()\n",
                "    train_loss = 0.0\n",
                "\n",
                "    for X_batch, y_batch in train_loader:\n",
                "        optimizer.zero_grad()\n",
                "        y_pred = model(X_batch)\n",
                "        loss = criterion(y_pred, y_batch)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        train_loss += loss.item() * X_batch.size(0)\n",
                "\n",
                "    train_loss /= len(train_loader.dataset)\n",
                "    \n",
                "    # Validation loop\n",
                "    model.eval()\n",
                "    val_loss = 0.0\n",
                "    with torch.no_grad():\n",
                "        for X_batch, y_batch in test_loader:\n",
                "            y_pred = model(X_batch)\n",
                "            loss = criterion(y_pred, y_batch)\n",
                "            val_loss += loss.item() * X_batch.size(0)\n",
                "    val_loss /= len(test_loader.dataset)\n",
                "\n",
                "    if (epoch+1) % 5 == 0:\n",
                "        print(f\"Epoch {epoch+1}/{n_epochs}: Train Loss={train_loss:.6f}, Val Loss={val_loss:.6f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a9566830-a936-42c2-950a-c7351778f81a",
            "metadata": {},
            "source": [
                "#### Recursive Forecast Logic"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7d75f5be-0e07-48ed-9e9e-b95c3cbf0b77",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-12-22T13:47:07.145847Z",
                    "iopub.status.busy": "2025-12-22T13:47:07.145093Z",
                    "iopub.status.idle": "2025-12-22T13:47:07.151598Z",
                    "shell.execute_reply": "2025-12-22T13:47:07.150868Z",
                    "shell.execute_reply.started": "2025-12-22T13:47:07.145814Z"
                },
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# 7. Recursive Forecasting Function\n",
                "def recursive_forecast_from_test(start_seq_idx, horizon=24):\n",
                "    \"\"\"\n",
                "    Performs multi-step recursive forecasting using the test set.\n",
                "    \"\"\"\n",
                "    # Initialize the first window\n",
                "    window = X_test_seq[start_seq_idx].copy()\n",
                "    \n",
                "    predictions_scaled = []\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        for step in range(horizon):\n",
                "            # 1. Predict the next hour\n",
                "            x_tensor = torch.tensor(window, dtype=torch.float32).unsqueeze(0).to(device)\n",
                "            y_pred = model(x_tensor)\n",
                "            y_pred_val = y_pred.item()\n",
                "            predictions_scaled.append(y_pred_val)\n",
                "            \n",
                "            # 2. Update the window for the next step (Sliding Window)\n",
                "            next_window = np.zeros_like(window)\n",
                "            \n",
                "            # Shift everything to the left\n",
                "            next_window[:-1, :] = window[1:, :]\n",
                "            \n",
                "            # 3. Fill the last position with new data\n",
                "            # Retrieve future features (Time, Temp) from the original scaled test set\n",
                "            t_index = start_seq_idx + sequence_length + step\n",
                "            \n",
                "            # Safety check to avoid index out of bounds\n",
                "            if t_index >= len(X_test_scaled):\n",
                "                break\n",
                "                \n",
                "            future_feat = X_test_scaled[t_index].copy()\n",
                "            \n",
                "            # Replace the demand feature (col 0) with our prediction\n",
                "            future_feat[0] = y_pred_val\n",
                "            \n",
                "            # Place into the window\n",
                "            next_window[-1, :] = future_feat\n",
                "            \n",
                "            window = next_window\n",
                "            \n",
                "    return np.array(predictions_scaled)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "36daa581",
            "metadata": {},
            "source": [
                "#### Results & Visualization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "dbb45400",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-12-22T13:48:39.661868Z",
                    "iopub.status.busy": "2025-12-22T13:48:39.661178Z",
                    "iopub.status.idle": "2025-12-22T13:48:39.915046Z",
                    "shell.execute_reply": "2025-12-22T13:48:39.914509Z",
                    "shell.execute_reply.started": "2025-12-22T13:48:39.661836Z"
                },
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Performance for 48 hours horizon:\n",
                        "RMSE: 1160.98 MW\n",
                        "MAE:  24.37 MW\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "<Figure size 1200x600 with 1 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# 8. Evaluation & Visualization\n",
                "TEST_START_IDX = 0        # Index to start forecasting from\n",
                "FORECAST_HORIZON = 48     # Hours to predict\n",
                "\n",
                "# --- Generate Predictions ---\n",
                "preds_scaled = recursive_forecast_from_test(TEST_START_IDX, horizon=FORECAST_HORIZON)\n",
                "preds_mw = scaler_y.inverse_transform(preds_scaled.reshape(-1, 1))\n",
                "\n",
                "# --- Retrieve Ground Truth ---\n",
                "gt_start_idx = TEST_START_IDX + sequence_length\n",
                "gt_end_idx = gt_start_idx + FORECAST_HORIZON\n",
                "\n",
                "y_true_scaled = y_test_scaled[gt_start_idx : gt_end_idx]\n",
                "y_true_mw = scaler_y.inverse_transform(y_true_scaled)\n",
                "\n",
                "# --- Metrics ---\n",
                "rmse = mean_squared_error(y_true_mw, preds_mw)\n",
                "mae = mean_absolute_error(y_true_mw, preds_mw)\n",
                "print(f\"Performance for {FORECAST_HORIZON} hours horizon:\")\n",
                "print(f\"RMSE: {rmse:.2f} MW\")\n",
                "print(f\"MAE:  {mae:.2f} MW\")\n",
                "\n",
                "# --- Plot ---\n",
                "plt.figure(figsize=(12, 6))\n",
                "plt.plot(y_true_mw, label='Ground Truth', marker='.', color='black')\n",
                "plt.plot(preds_mw, label='Recursive Forecast', color='red', linestyle='--')\n",
                "plt.title(f'Multi-step Forecast: Next {FORECAST_HORIZON} Hours')\n",
                "plt.ylabel('Energy Demand (MW)')\n",
                "plt.xlabel('Hours into the Future')\n",
                "plt.legend()\n",
                "plt.grid(True, alpha=0.3)\n",
                "plt.style.use('dark_background')\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kaggle": {
            "accelerator": "nvidiaTeslaT4",
            "dataSources": [
                {
                    "datasetId": 1307335,
                    "sourceId": 2177559,
                    "sourceType": "datasetVersion"
                }
            ],
            "dockerImageVersionId": 31236,
            "isGpuEnabled": true,
            "isInternetEnabled": true,
            "language": "python",
            "sourceType": "notebook"
        },
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}